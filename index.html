<!DOCTYPE html>
<!-- saved from url=(0030)https://geng-haoran.github.io/ -->
<html lang="en"><!-- head --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <script>
    (function () {
        var a_idx = 0;
        window.onclick = function (event) {
            var a = new Array("✨", "🤖", "🥳", "👋", "💓", "🐽", "👽", "😻", "💪");

            var heart = document.createElement("b");
            heart.onselectstart = new Function('event.returnValue=false');

            document.body.appendChild(heart).innerHTML = a[a_idx];
            a_idx = (a_idx + 1) % a.length;
            heart.style.cssText = "position: fixed;left:-100%;";

            var f = 16, 
                x = event.clientX - f / 2, 
                y = event.clientY - f,
                c = randomColor(), 
                a = 1,
                s = 1.2; 

            var timer = setInterval(function () { 
                if (a <= 0) {
                    document.body.removeChild(heart);
                    clearInterval(timer);
                } else {
                    heart.style.cssText = "font-size:16px;cursor: default;position: fixed;color:" +
                        c + ";left:" + x + "px;top:" + y + "px;opacity:" + a + ";transform:scale(" +
                        s + ");";

                    y--;
                    a -= 0.016;
                    s += 0.002;
                }
            }, 15)

        }
        function randomColor() {

            return "rgb(" + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + "," + (~~(Math
            .random() * 255)) + ")";

        }
    }());
  </script>

  <!-- Google tag (gtag.js) -->
  <script async="" src="./style/js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-66DNLPJ6PY');
  </script>

  
  <title>Jiaxu Zhang   |  张嘉旭</title>
  
  <meta name="author" content="Jiaxu Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="./style/stylesheet.css">
	<link rel="icon" type="image/png" href="./style/icon.png">
<script type="text/javascript">
  function hideshow(which){
  if (!document.getElementById)
  return
  if (which.style.display=="block")
  which.style.display="none"
  else
  which.style.display="block"
  }
</script><meta http-equiv="origin-trial" content="AymqwRC7u88Y4JPvfIF2F37QKylC04248hLCdJAsh8xgOfe/dVJPV3XS3wLFca1ZMVOtnBfVjaCMTVudWM//5g4AAAB7eyJvcmlnaW4iOiJodHRwczovL3d3dy5nb29nbGV0YWdtYW5hZ2VyLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjk1MTY3OTk5LCJpc1RoaXJkUGFydHkiOnRydWV9"></head>

<!-- bib hide -->


<!-- body -->
<body data-new-gr-c-s-check-loaded="14.1056.0" data-gr-ext-installed="">
  <!-- self-intro -->
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2%;width:55%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jiaxu Zhang | 张嘉旭</name>
              </p>
              <p style="text-align: justify">
              <intro>
                I am a <b>Ph.D. student</b> working with <a href="https://en.whu.edu.cn/info/1073/1569.htm">Prof. Deren Li</a> and <a href="http://tuzhigang.cn/">Prof. Zhigang Tu</a>  in LIESMARS at <b>Wuhan University</b>, China. Before that, I received my B.S. degree from Southeast University in 2020 and MEng from Wuhan University in 2023.
                <br>
                I worked as a research intern at <b>Tencent</b> from 2022 to 2024. Currently, I am interning at <b>StepFun</b>, collaborating with <a href="https://www.skicyyu.org/">Dr. Gang Yu</a> on AIGC research. My research interest lies in deep learning, computer vision and computer graphics, with a current focus on 3D/2D animation, motion generation, retargeting, and recognition.  
              </intro>
              <p>
                Expected graduation in 2026, open to postdoc and research scientist positions.
              </p>
              <p style="text-align:center">
                <a href="mailto:zjuaxu@whu.edu.com">Email</a> &nbsp;/&nbsp;
                <a href="data/JiaxuZhang-CV-2024.pdf">CV</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com.hk/citations?user=jUAyNjEAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://github.com/Kebii/">Github</a> &nbsp;/&nbsp;
                <a href="images/wechat.jpg">WeChat</a>
              </p>
            </td>
            <td style="padding:0%; width:26%; max-width:26%;"> <!-- move the photo a bit left -->
              <br>
              <!-- <br> -->
              <img style="padding:1%; width:60%; max-width:60%;  display: block; margin-left: auto; margin-right: auto; " alt="profile photo" src="./images/jiaxuzhang.jpg" class="hoverZoomLink">
            </td>
            <!-- <td style="padding:5%;width:37%;max-width:37%"> 
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/face3.jpg" class="hoverZoomLink">
              <a href="https://hits.seeyoufarm.com" target="_blank"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgeng-haoran.github.io&count_bg=%23FF8400&title_bg=%23545353&icon=tableau.svg&icon_color=%23F3F209&title=hits&edge_flat=false"/></a>
            </td> -->
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    
  </tbody></table>

  <!-- News -->
  <heading>News</heading><br><table style="width:90%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
    <!-- <br> -->
    
    
    <tr><td style="padding:0px;width:100%;vertical-align:middle">
      <p>
      </p>
      <li>[2024/07] 🎉 One paper gets accepted to ACM MM 2024.</li>
    <p></p> 
      <p>
      </p>
      <li>[2024/04] 🕹️ I've released a repository, <a href='https://github.com/Kebii/Freehand-Genshin-Diffusion'>Freehand-Genshin-Diffusion</a>, that transforms Genshin PVs into a freehand style using the Diffusion Model. Feel free to give it a try!</li>
    <p></p> 
      <p>
      </p>
      <li>[2024/04] 🎉 One paper has been accepted by IEEE T-PAMI, which is an extension of our CVPR 2023 paper.</li>
    <p></p> 
    <p>
      </p>
      <li>[2024/01] 🎉 One paper gets accepted to ICLR 2024.</li>
    <p></p> 
    <p>
    </p>
    <li>[2023/06] 📌 I gave an oral presentation on Virtual Animation Technology at VALSE 2023.</li>
  <p></p> 
    <p>
    </p>
    <li>[2023/02] 🎉 One paper gets accepted to CVPR 2023.</li>
  <p></p> 
  </td>
  </tr>
  </tbody></table>

  <!-- Research -->
  <br><heading>Research</heading><br><p>
      My research interests are broadly in <strong>3D/2D Computer Vision</strong> and <strong>Computer Animation</strong>. My overarching research objective is to contribute to the development of lifelike, intelligent, and interactive virtual avatars and animations.

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    
    
    <!--  ----------------------------------------------------------------------------------------------------------------------------------- -->
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/mikudance.gif' height="150" width="200">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://kebii.github.io/MikuDance/">
          <span class="papertitle">MikuDance: Animating Character Art with Mixed Motion Dynamics</span>
        </a>
        <br>
        <strong>Jiaxu Zhang</strong>, Xianfang Zeng, Xin Chen, Wei Zuo, Gang Yu*, Zhigang Tu*
        <br>
        <em>Arxiv</em>, 2024
        <br>
        <a href="https://kebii.github.io/MikuDance/">project page </a> / <a href="https://github.com/Kebii/MikuDance">code (coming soon) </a> / <a href="https://arxiv.org/abs/2411.08656">arxiv </a>
        <p></p>
        <p>We propose MikuDance, a diffusion-based pipeline incorporating mixed motion dynamics to animate stylized character art.</p>
      </td>
    </tr>
    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/paint_gensin.jpg' height="150" width="200">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://github.com/Kebii/Freehand-Genshin-Diffusion">
          <span class="papertitle">Freehand-Genshin-Diffusion</span>
        </a>
        <br>
        <p>A project for transforming Genshin PVs into a freehand style using Diffusion Model.</p>
        <p>I've been exploring 2D image animation recently. This project is purely for fun. Feel free to reach out and discuss this with me.</p>
      </td>
    </tr>
    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/mret.jpg' height="150" width="200">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/10495176">
          <span class="papertitle">A Modular Neural Motion Retargeting System Decoupling Skeleton and Shape Perception</span>
        </a>
        <br>
        <strong>Jiaxu Zhang</strong>, Zhigang Tu*, Junwu Weng, Junsong Yuan, Bo Du
        <br>
        <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>T-PAMI</strong>)</em>, 2024
        <br>
        <a href="https://github.com/Kebii/R2ET/">code </a> / <a href="">arxiv </a>
        <p></p>
        <p>M-R2ET is a modular neural motion retargeting system designed to transfer motion between characters with different structures but corresponding to homeomorphic graphs, meanwhile preserving motion semantics and perceiving shape geometries.</p>
      </td>
    </tr>

  <tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src='images/motions.jpg' height="150" width="200">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://arxiv.org/pdf/2403.11469.pdf">
      <span class="papertitle">Generative Motion Stylization of Cross-structure Characters within Canonical Motion Space</span>
    </a>
    <br>
    <strong>Jiaxu Zhang</strong>, Xin Chen, Gang Yu, Zhigang Tu*
    <br>
    <em>Proceedings of the 32nd ACM International Conference on Multimedia (<strong>ACM MM</strong>)</em>, 2024
    <br>
   <a href="https://arxiv.org/abs/2403.11469">arxiv </a>
    <p></p>
    <p>We present MotionS, a generative motion stylization pipeline for synthesizing diverse and stylized motion on cross-structure source using cross-modality style prompts.</p>
  </td>
</tr>

<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src='images/tapmo.jpg' height="150" width="200">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://semanticdh.github.io/TapMo/">
      <span class="papertitle">TapMo: Shape-aware Motion Generation of Skeleton-free Characters</span>
    </a>
    <br>
    <strong>Jiaxu Zhang#</strong>, Shaoli Huang#, Zhigang Tu*, Xin Chen, Xiaohang Zhan, Gang Yu, Ying Shan
    <br>
    <em>The Twelfth International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2024
    <br>
    <a href="https://semanticdh.github.io/TapMo/">project page </a> / <a href="https://github.com/Kebii/TapMo">code </a> / <a href="https://arxiv.org/abs/2310.12678">arxiv </a>
    <p></p>
    <p>TapMo is a text-based animation pipeline for generating motion in a wide variety of skeleton-free characters.</p>
  </td>
</tr>

<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src='images/r2et.jpg' height="150" width="200">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Skinned_Motion_Retargeting_With_Residual_Perception_of_Motion_Semantics__CVPR_2023_paper.html">
      <span class="papertitle">Skinned Motion Retargeting with Residual Perception of Motion Semantics & Geometry</span>
    </a>
    <br>
    <strong>Jiaxu Zhang</strong>, Junwu Weng, Di Kang, Fang Zhao, Shaoli Huang, Xuefei Zhe, Linchao Bao, Ying Shan, Jue Wang, Zhigang Tu*
    <br>
    <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2023
    <br>
    <a href="https://semanticdh.github.io/R2ET/">project page </a> / <a href="https://github.com/Kebii/R2ET/">code</a> / <a href="https://arxiv.org/abs/2303.08658">arxiv </a>
    <p></p>
    <p>R2ET is a neural motion retargeting model that can preserve the source motion semantics and avoid interpenetration in the target motion.</p>
  </td>
</tr>

<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src='images/zt.jpg' height="150" width="200">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://ieeexplore.ieee.org/document/9845486">
      <span class="papertitle">Zoom Transformer for Skeleton-based Group Activity Recognition</span>
    </a>
    <br>
    <strong>Jiaxu Zhang</strong>, Yifan Jia, Wei Xie, and Zhigang Tu*
    <br>
    <em>IEEE Transactions on Circuits and Systems for Video Technology (<strong>T-CSVT</strong>)</em>, 2022
    <br>
    <a href="https://github.com/Kebii/Zoom-Transformer">code</a> / <a href="">arxiv</a>
    <p></p>
    <p>We propose a novel Zoom Transformer to exploit both the low-level single-person motion information and the high-level multi-person interaction information in a uniform attention structure.</p>
  </td>
</tr>

<tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <img src='images/jbfgcn.jpg' height="150" width="200">
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://ieeexplore.ieee.org/document/9772775">
      <span class="papertitle">Joint-bone Fusion Graph Convolutional Network for Semi-supervised Skeleton Action Recognition</span>
    </a>
    <br>
    Zhigang Tu#, <strong>Jiaxu Zhang#*</strong>, Hongyan Li, Yujin Chen, and Junsong Yuan
    <br>
    <em>IEEE Transactions on Multimedia (<strong>T-MM</strong>)</em>, 2022
    <br>
    <a href="">code</a> / <a href="https://arxiv.org/abs/2202.04075">arxiv</a>
    <p></p>
    <p>we propose a semi-supervised skeleton-based action recognition method.</p>
  </td>
</tr>
<!--  ----------------------------------------------------------------------------------------------------------------------------------- -->

  </tbody></table>

  <!-- Services -->
  <!-- <br><heading>Services</heading><br><table style="width:90%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        
        
        
      <td style="padding:0px;width:100%;vertical-align:middle">
        <p>
          </p><li>Reviewer: SIGGRAPH, NeurIPS, AAAI</li>
        <p></p>
      </td>
    </tr>
  </tbody></table> -->

  <!-- Experience -->
  <br><heading>Experience</heading><br><br><table width="100%" align="center" border="0" cellpadding="10"><tbody>
      
    <tr>
      <td style="padding-left:18px;padding-right:20px;width:20%;vertical-align:middle"><img src="./images/step_logo.png" ,="" width="105"></td>
      <td width="100%" valign="center">
        <strong><a href="https://www.stepfun.com/" target="_blank"><papertitle>StepFun</papertitle> </a></strong>
        <br> <em>2024.05 - Present, Shanghai</em><br>  <strong>Research Intern</strong> for AIGC. Advisor: Dr. <a href="https://www.skicyyu.org/" target="_blank">Gang Yu</a> and Dr. <a href="https://scholar.google.com/citations?user=tgDc0fsAAAAJ&hl=en" target="_blank">Xianfang Zeng</a>
      </td>
    </tr> 
      
      <tr>
        <td style="padding-left:18px;padding-right:20px;width:20%;vertical-align:middle"><img src="./images/whu.png" ,="" width="105"></td>
        <td width="100%" valign="center">
          <strong><a href="https://www.whu.edu.cn/" target="_blank"><papertitle>Wuhan University</papertitle> </a></strong>
          <br> <em>2020.09 - Present, Wuhan</em><br>  <strong>Ph.D Student</strong> in LIEMSARS.
          <br>I received my <strong>Master Degree</strong> of Computer Technology in 2023. 
          <!-- <br> <em>2023.06 - 2023.09 (expected)</em> <br> <strong>Student of</strong> <a href="https://engineering.stanford.edu/students-academics/programs/global-engineering-programs/chinese-ugvr/">UGVR Program </a>  -->
          <br> Research Advisor: Prof. <a href="https://http://tuzhigang.cn/" target="_blank">Zhigang Tu</a>
        </td>
      </tr>

      <tr>
        <td style="padding-left:18px;padding-right:20px;width:20%;vertical-align:middle"><img src="./images/tencent_logo.png" ,="" width="105"></td>
        <td width="100%" valign="center">
          <strong><a href="https://ai.tencent.com/" target="_blank"><papertitle>Tencent</papertitle> </a></strong>
          <br> <em>2023.06 - 2024.04, Shanghai</em><br>  <strong>Research Intern</strong> in Tencent PCG. Advisor: Dr. <a href="https://www.skicyyu.org/" target="_blank">Gang Yu</a> and Dr. <a href="https://chenxin.tech/" target="_blank">Xin Chen</a>
          <br> <em>2022.07 - 2023.06, Shenzhen</em><br>  <strong>Research Intern</strong> in Tencent AI Lab. Advisor: Dr. <a href="https://calcifer.me/" target="_blank">Junwu Weng</a> and Dr. <a href="https://scholar.google.com/citations?user=o31BPFsAAAAJ&hl=zh-CN" target="_blank">Shaoli Huang</a>
        </td>
      </tr>

      <tr>
        <td style="padding-left:18px;padding-right:20px;width:20%;vertical-align:middle"><img src="./images/seu.png" ,="" width="105"></td>
        <td width="100%" valign="center">
          <strong><a href="https://www.seu.edu.cn/" target="_blank"><papertitle>Southeast University</papertitle> </a></strong>
          <br> <em>2016.09 - 2020.06, Nanjing</em><br>  I received my <strong>B.S Degree</strong> of Geographic Information Science in 2020. GPA: 3.88/4.0, Rank: 1/26.
          <br> <em>2018.11 - 2020.06, Nanjing</em><br>  <strong>Research assistant</strong> in Research Center of Complex Transportation Network (TLab).
        </td>
      </tr> 
        
  </tbody></table>

  <!-- Selected Awards and Honors -->
  <br><heading>Awards and Honors</heading><br><table style="width:90%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          

        <tr><td style="padding:0px;width:100%;vertical-align:middle">
          <p>
          </p><li>2024: NSFC Youth Scholars Basic Research Project </a> (300,000RMB¥)</li>
        <p></p>
          <p>
          </p><li>2023: <a href="https://www.sohu.com/a/745941721_121123740"> Lei Jun Excellence Scholarship </a> (<strong>100,000RMB¥, Top 0.1‰</strong>)</li>
        <p></p>
          <p>
          </p><li>2023: Wang Zhizhuo Innovative Talent Award (8,000RMB¥, Top 1%)</li>
        <p></p>
          <p>
          </p><li>2022: National Scholarship (<strong>Highest Honor</strong> for Master students in China, 10,000RMB¥, Top 3%)</li>
        <p></p>
          <p>
          </p><li>2022: First-class Scholarship of Wuhan University (5,000RMB¥, Top 10%)</li>
        <p></p>
          <p>
          </p><li>2021: First-class Scholarship of Wuhan University (5,000RMB¥, Top 10%)</li>
        <p></p>
          <p>
          </p><li>2021: 1<sup>st</sup> Runner-up of <a href="https://sutdcv.github.io/multi-modal-video-reasoning/#/leaderboard">ICCV 2021 MMVRAC Challenge</a> (Track 2 and Track 3)</li>
        <p></p>
          <p>
          </p><li>2020: Outstanding graduates of Southeast University (Top 3%)</li>
        <p></p>
          <p>
          </p><li>2019: Meritorious Winner - Mathematical Contest In Modeling & Interdisciplinary Contest In Modeling, 2019</li>
        <p></p>
          <p>
          </p><li>2018: National Scholarship (<strong>Highest Honor</strong> for undergraduates in China, 8,000RMB¥, Top 3%)</li>
        <p></p>
        </td>
      </tr>
  </tbody></table>

  <hr>
  <p align="center">
    <a href="https://clustrmaps.com/site/1bbtb" title="Visit tracker"><img src="//clustrmaps.com/map_v2.png?cl=be8670&w=400&t=tt&d=qZS4ggcBQIgR4I9SYbVQoi-6xMTgYyMGlUnPAq-jWv4&co=ffffff&ct=bd5d38" /></a>
  </p>

  <!-- Aknowledgements -->
  <p style="text-align:center">
          This homepage is designed based on <a href="https://jonbarron.info/">Jon Barron</a>'s website and deployed on <a href="https://pages.github.com/">Github Pages</a>. Last updated: Jun. 17, 2024

          <br>
          © 2024 Jiaxu Zhang
        </p><table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <!-- <br> -->
      <!-- <br> -->
      
        
      
      </tr>
  </tbody></table>
 


</td></tr></tbody></table></body><grammarly-desktop-integration data-grammarly-shadow-root="true"><template shadowrootmode="open"><style>
      div.grammarly-desktop-integration {
        position: absolute;
        width: 1px;
        height: 1px;
        padding: 0;
        margin: -1px;
        overflow: hidden;
        clip: rect(0, 0, 0, 0);
        white-space: nowrap;
        border: 0;
        -moz-user-select: none;
        -webkit-user-select: none;
        -ms-user-select:none;
        user-select:none;
      }

      div.grammarly-desktop-integration:before {
        content: attr(data-content);
      }
    </style><div aria-label="grammarly-integration" role="group" tabindex="-1" class="grammarly-desktop-integration" data-content="{&quot;mode&quot;:&quot;full&quot;,&quot;isActive&quot;:true,&quot;isUserDisabled&quot;:false}"></div></template></grammarly-desktop-integration></html>